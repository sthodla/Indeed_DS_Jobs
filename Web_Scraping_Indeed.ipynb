{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_links(l, start, end):\n",
    "    \"\"\"give the head of the link the start number and the end number and return a list of links to indeed.\"\"\"\n",
    "    links = [l + str(i) for i in range(start, end+1, 10)]\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_html(link):\n",
    "    \"\"\"present the link and return a beautiful soup object that contains the html\"\"\"\n",
    "    url = requests.get(link)\n",
    "    s = BeautifulSoup(url.content, 'html.parser')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_jobnames(s):\n",
    "    \"\"\"return a list a job positions given the soup object\"\"\"\n",
    "    j = []\n",
    "    for div in s.find_all(name='div', attrs={'class':'row'}):\n",
    "        for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "            j.append(a['title'])\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_comp(s):\n",
    "    \"\"\"return a list of company names given the soup object\"\"\"\n",
    "    c = []\n",
    "    for link in s.find_all('span', attrs = {'class': 'company'}):\n",
    "        c.append(link.getText().lstrip())\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loc(s):\n",
    "    \"\"\"return a list of locations given the soup object\"\"\"\n",
    "    l = []\n",
    "    for link in s.find_all('div'):\n",
    "        for key, value, in link.attrs.items():\n",
    "            if key == 'data-rc-loc':\n",
    "                l.append(value)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_df(links):\n",
    "    \"\"\"create a dataframe of 3 columns: job position, company name, location of the company given a list of \n",
    "        links\"\"\"\n",
    "    comps = []\n",
    "    pos = []\n",
    "    locs = []\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for idx, link in tqdm(enumerate(links)):\n",
    "        soup = get_html(link)\n",
    "        comps.append(get_comp(soup))\n",
    "        locs.append(get_loc(soup))\n",
    "        pos.append(get_jobnames(soup))\n",
    "        df = pd.concat([df, pd.DataFrame([pos[idx], comps[idx], locs[idx]]).T])\n",
    "    \n",
    "    df.columns = ['position', 'company', 'location']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [02:09,  1.29s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SENIOR DATA OPERATIONS ENGINEER</td>\n",
       "      <td>NetWise Data</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>Curotec</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Platform Engineer</td>\n",
       "      <td>KeepTruckin</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hadoop Spark Data Engineer</td>\n",
       "      <td>ITI Data</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Systems Engineer</td>\n",
       "      <td>Entre Technology Services</td>\n",
       "      <td>Bozeman, MT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          position                    company  \\\n",
       "0  SENIOR DATA OPERATIONS ENGINEER               NetWise Data   \n",
       "1                Big Data Engineer                    Curotec   \n",
       "2           Data Platform Engineer                KeepTruckin   \n",
       "3       Hadoop Spark Data Engineer                   ITI Data   \n",
       "4                 Systems Engineer  Entre Technology Services   \n",
       "\n",
       "            location  flag  \n",
       "0      San Diego, CA     1  \n",
       "1   Philadelphia, PA     1  \n",
       "2  San Francisco, CA     1  \n",
       "3        Chicago, IL     1  \n",
       "4        Bozeman, MT     1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I checked that 1000 is the 100th page of indeed and its also the last page so these numbers should be fine\n",
    "#all you need to do is change the parameter q from data scientist to data engineer etc.\n",
    "df = make_df(get_links('https://www.indeed.com/jobs?q=data+engineer&radius=100&start=', 10, 1000))\n",
    "df['flag'] = 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = df[['position','company','location','flag']].groupby(['position', 'company','location']).sum().sort_values(by = 'flag',ascending = False).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First time writing the dataframe to csv use this following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t.to_csv('/Users/dillonquan/Desktop/DataVizProject/indeed_2019.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this cell when you have already created your csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/dillonquan/Desktop/DataVizProject/indeed_2019.csv', 'a') as f:\n",
    "    t.to_csv(f, header = False, index = False, mode = 'a',line_terminator = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOP HERE!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfl = make_df(get_links('https://www.indeed.com/jobs?q=data+analytics&radius=100&start=', 110, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfl['flag'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quality Analyst</td>\n",
       "      <td>Alameda Health System</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122 HEALTHCARE ANALYTICS - Manager Analytics</td>\n",
       "      <td>Alameda Alliance</td>\n",
       "      <td>Alameda, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data &amp; Analytics Information Architect</td>\n",
       "      <td>Procter &amp; Gamble</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HR Data &amp; Analytics Manager</td>\n",
       "      <td>Anheuser-Busch</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Faculty Chair - Analytics &amp; Big Data Program</td>\n",
       "      <td>Executive Education Institute</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       position  \\\n",
       "0                               Quality Analyst   \n",
       "1  122 HEALTHCARE ANALYTICS - Manager Analytics   \n",
       "2        Data & Analytics Information Architect   \n",
       "3                   HR Data & Analytics Manager   \n",
       "4  Faculty Chair - Analytics & Big Data Program   \n",
       "\n",
       "                         company           location  flag  \n",
       "0          Alameda Health System        Oakland, CA     1  \n",
       "1               Alameda Alliance        Alameda, CA     1  \n",
       "2               Procter & Gamble     Cincinnati, OH     1  \n",
       "3                 Anheuser-Busch      St. Louis, MO     1  \n",
       "4  Executive Education Institute  San Francisco, CA     1  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.concat([df, dfl])\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1855 entries, 0 to 18\n",
      "Data columns (total 4 columns):\n",
      "position    1855 non-null object\n",
      "company     1854 non-null object\n",
      "location    1855 non-null object\n",
      "flag        1855 non-null int64\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 72.5+ KB\n"
     ]
    }
   ],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = d.groupby(['position', 'company','location']).count().sort_values('flag', ascending = False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 824 entries, 0 to 823\n",
      "Data columns (total 4 columns):\n",
      "position    824 non-null object\n",
      "company     824 non-null object\n",
      "location    824 non-null object\n",
      "flag        824 non-null int64\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 25.8+ KB\n"
     ]
    }
   ],
   "source": [
    "t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t.to_csv('/Users/dillonquan/Desktop/DataVizProject/indeed_2019.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial and Errors Just ignore anything following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['National Security Agency',\n",
       " 'Sony Pictures Entertainment Inc.',\n",
       " 'Grand Rounds',\n",
       " 'Digitalogy',\n",
       " 'Pieces Technologies',\n",
       " 'LIVE OBJECTS',\n",
       " 'National Security Agency',\n",
       " 'Adwait',\n",
       " 'Virta Health',\n",
       " 'Walmart',\n",
       " 'Walmart eCommerce',\n",
       " 'Hireup Resources',\n",
       " 'Trimark Associates, Inc.',\n",
       " 'Soaren Management',\n",
       " 'Verizon',\n",
       " 'Apple',\n",
       " 'Seen by Indeed',\n",
       " 'Valassis Digital']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps1 = []\n",
    "soup = get_html(links[4])\n",
    "for com in soup.find_all('span', attrs = {'class': 'company'}):\n",
    "    comps1.append(com.getText().lstrip())\n",
    "comps1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Soaren Management',\n",
       " 'Verizon',\n",
       " 'Grokstream',\n",
       " 'Facebook',\n",
       " 'Osmo',\n",
       " 'Crossover Health',\n",
       " 'HG Insights',\n",
       " 'Walmart',\n",
       " 'Neal Analytics',\n",
       " 'Brain Corp',\n",
       " 'Yang2020',\n",
       " 'Tempus',\n",
       " 'Disney Streaming Services',\n",
       " 'Hireup Resources',\n",
       " 'Trimark Associates, Inc.',\n",
       " 'Apple',\n",
       " 'Seen by Indeed',\n",
       " 'Valassis Digital',\n",
       " 'National Security Agency']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps2 = []\n",
    "soup = get_html(links[8])\n",
    "for com in soup.find_all('span', attrs = {'class': 'company'}):\n",
    "    comps2.append(com.getText().lstrip())\n",
    "comps2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "comps = []\n",
    "for link in tqdm(links):\n",
    "    soup = get_html(link)\n",
    "    for com in soup.find_all('span', attrs = {'class': 'company'}):\n",
    "        comps.append(com.getText().lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs = []\n",
    "for link in tqdm(links):\n",
    "    soup = get_html(link)\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "            jobs.append(a['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 425.75it/s]\n"
     ]
    }
   ],
   "source": [
    "locs = []\n",
    "for link in tqdm(links):\n",
    "    for loc in soup.find_all('div'):\n",
    "        for key, value, in loc.attrs.items():\n",
    "            if key == 'data-rc-loc':\n",
    "                locs.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp = []\n",
    "for link in soup.find_all('span', attrs = {'class': 'company'}):\n",
    "    comp.append(link.getText().lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y), len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loc = []\n",
    "for link in soup.find_all('div'):\n",
    "    for key, value, in link.attrs.items():\n",
    "        if key == 'data-rc-loc':\n",
    "            loc.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for link in soup.findAll('a', attrs={'href'}):\n",
    "\n",
    "#pattern = re.compile(\"^http://www.indeed.com/pagead*\")\n",
    "l = []\n",
    "for div in soup.find_all('div', attrs={'class':'title'}):\n",
    "    for link in div.find_all('a', attrs={'href': re.compile(\"^/pagead.*\")}):\n",
    "        l.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "companies = []\n",
    "for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "    company = div.find_all(name='span', attrs={'class':'company'})\n",
    "    if len(company) > 0:\n",
    "        for b in company:\n",
    "            companies.append(b.text.strip())\n",
    "    else:\n",
    "        sec_try = div.find_all(name='span', attrs={'class':'result-link-source'})\n",
    "        for span in sec_try:\n",
    "            companies.append(span.text.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
