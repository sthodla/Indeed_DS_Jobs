{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "indeed = pd.read_csv('indeed_Lin_Reg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below function is to help label data as Data Science related or not, which is our response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(s):\n",
    "    \"\"\"categorizes the job position to bins of SEAM (scientist, data engineer, analyst, ML)\"\"\"\n",
    "    \n",
    "    patterns = ['.*data sci.*','.*data.*eng.*', '.*analy.*', '.*machine.*']\n",
    "    for idx, pattern in enumerate(patterns):\n",
    "        reg = re.compile(pattern)\n",
    "        if reg.search(s):\n",
    "            return idx\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't want missing data, so drop those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeed = indeed[~indeed.position.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Text and label data (using one hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeed['position'] = indeed['position'].apply(lambda x : x.lower())\n",
    "        \n",
    "indeed['label'] = -1\n",
    "for idx, row in indeed.iterrows():\n",
    "    cat = categorize(row.position)\n",
    "    if cat != -1:\n",
    "        indeed.loc[idx, 'label'] = 'DS'\n",
    "    else:\n",
    "        indeed.loc[idx, 'label'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeed, test = train_test_split(indeed, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to make the formula, have to change c# to c_sharp and scikit-learn to scikit_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = list(indeed.columns).index('c#')\n",
    "indeed.columns = list(indeed.columns)[:indx] + ['c_sharp'] + list(indeed.columns)[indx+1:]\n",
    "indx = list(indeed.columns).index('scikit-learn')\n",
    "indeed.columns = list(indeed.columns)[:indx] + ['scikit_learn'] + list(indeed.columns)[indx+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label ~ python + r + sql + spark + hadoop + java + sas + tableau + hive + scala + c++ + aws + tensorflow + matlab + c + excel + linux + nosql + azure + scikit_learn + spss + pandas + numpy + pig + d3 + keras + javascript + c_sharp + perl + hbase + docker + git + mysql + mongodb + cassandra + pytorch + caffe\n"
     ]
    }
   ],
   "source": [
    "formula = 'label ~ ' + ' + '.join(list(indeed.columns)[5:42])\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.glm(formula, data=indeed, family=sm.families.Binomial()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>  <td>['label[DS]', 'label[Other]']</td> <th>  No. Observations:  </th>  <td>  5214</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                       <td>GLM</td>              <th>  Df Residuals:      </th>  <td>  5177</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>             <td>Binomial</td>            <th>  Df Model:          </th>  <td>    36</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>              <td>logit</td>             <th>  Scale:             </th> <td>  1.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                     <td>IRLS</td>              <th>  Log-Likelihood:    </th> <td> -2833.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                 <td>Fri, 11 Oct 2019</td>        <th>  Deviance:          </th> <td>  5666.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                     <td>19:29:57</td>            <th>  Pearson chi2:      </th> <td>5.39e+03</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>               <td>5</td>               <th>  Covariance Type:   </th> <td>nonrobust</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   -1.1686</td> <td>    0.049</td> <td>  -23.863</td> <td> 0.000</td> <td>   -1.265</td> <td>   -1.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>python</th>       <td>    1.0943</td> <td>    0.089</td> <td>   12.306</td> <td> 0.000</td> <td>    0.920</td> <td>    1.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>r</th>            <td>    0.2770</td> <td>    0.083</td> <td>    3.343</td> <td> 0.001</td> <td>    0.115</td> <td>    0.439</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sql</th>          <td>    1.0346</td> <td>    0.095</td> <td>   10.928</td> <td> 0.000</td> <td>    0.849</td> <td>    1.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spark</th>        <td>    0.4800</td> <td>    0.149</td> <td>    3.215</td> <td> 0.001</td> <td>    0.187</td> <td>    0.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hadoop</th>       <td>    0.4803</td> <td>    0.154</td> <td>    3.128</td> <td> 0.002</td> <td>    0.179</td> <td>    0.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>java</th>         <td>   -0.0399</td> <td>    0.115</td> <td>   -0.346</td> <td> 0.729</td> <td>   -0.266</td> <td>    0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sas</th>          <td>    0.5055</td> <td>    0.134</td> <td>    3.777</td> <td> 0.000</td> <td>    0.243</td> <td>    0.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tableau</th>      <td>    0.7742</td> <td>    0.166</td> <td>    4.672</td> <td> 0.000</td> <td>    0.449</td> <td>    1.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hive</th>         <td>    0.2589</td> <td>    0.206</td> <td>    1.255</td> <td> 0.209</td> <td>   -0.145</td> <td>    0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scala</th>        <td>    0.8433</td> <td>    0.175</td> <td>    4.828</td> <td> 0.000</td> <td>    0.501</td> <td>    1.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>c</th>            <td>   -0.1030</td> <td>    0.118</td> <td>   -0.876</td> <td> 0.381</td> <td>   -0.333</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aws</th>          <td>    0.0874</td> <td>    0.136</td> <td>    0.645</td> <td> 0.519</td> <td>   -0.178</td> <td>    0.353</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tensorflow</th>   <td>    1.0283</td> <td>    0.218</td> <td>    4.711</td> <td> 0.000</td> <td>    0.600</td> <td>    1.456</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>matlab</th>       <td>   -0.1733</td> <td>    0.129</td> <td>   -1.347</td> <td> 0.178</td> <td>   -0.425</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>excel</th>        <td>    0.3895</td> <td>    0.094</td> <td>    4.130</td> <td> 0.000</td> <td>    0.205</td> <td>    0.574</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>linux</th>        <td>   -0.3581</td> <td>    0.132</td> <td>   -2.704</td> <td> 0.007</td> <td>   -0.618</td> <td>   -0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nosql</th>        <td>   -0.3927</td> <td>    0.197</td> <td>   -1.995</td> <td> 0.046</td> <td>   -0.779</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>azure</th>        <td>   -0.8080</td> <td>    0.211</td> <td>   -3.836</td> <td> 0.000</td> <td>   -1.221</td> <td>   -0.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scikit_learn</th> <td>    0.1994</td> <td>    0.288</td> <td>    0.692</td> <td> 0.489</td> <td>   -0.365</td> <td>    0.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spss</th>         <td>    0.5977</td> <td>    0.213</td> <td>    2.805</td> <td> 0.005</td> <td>    0.180</td> <td>    1.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pandas</th>       <td>    1.0421</td> <td>    0.357</td> <td>    2.916</td> <td> 0.004</td> <td>    0.342</td> <td>    1.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numpy</th>        <td>   -0.1173</td> <td>    0.373</td> <td>   -0.315</td> <td> 0.753</td> <td>   -0.849</td> <td>    0.614</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pig</th>          <td>    1.1821</td> <td>    0.346</td> <td>    3.419</td> <td> 0.001</td> <td>    0.504</td> <td>    1.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d3</th>           <td>    0.5832</td> <td>    0.336</td> <td>    1.736</td> <td> 0.083</td> <td>   -0.075</td> <td>    1.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>keras</th>        <td>    0.9288</td> <td>    0.363</td> <td>    2.559</td> <td> 0.011</td> <td>    0.217</td> <td>    1.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>javascript</th>   <td>   -0.6604</td> <td>    0.166</td> <td>   -3.980</td> <td> 0.000</td> <td>   -0.986</td> <td>   -0.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>c_sharp</th>      <td>   -0.3356</td> <td>    0.189</td> <td>   -1.775</td> <td> 0.076</td> <td>   -0.706</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>perl</th>         <td>   -0.8921</td> <td>    0.166</td> <td>   -5.376</td> <td> 0.000</td> <td>   -1.217</td> <td>   -0.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hbase</th>        <td>    0.0494</td> <td>    0.362</td> <td>    0.137</td> <td> 0.891</td> <td>   -0.659</td> <td>    0.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>docker</th>       <td>   -0.7522</td> <td>    0.246</td> <td>   -3.058</td> <td> 0.002</td> <td>   -1.234</td> <td>   -0.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>git</th>          <td>   -0.0924</td> <td>    0.206</td> <td>   -0.448</td> <td> 0.654</td> <td>   -0.497</td> <td>    0.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mysql</th>        <td>    0.0138</td> <td>    0.246</td> <td>    0.056</td> <td> 0.955</td> <td>   -0.468</td> <td>    0.496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mongodb</th>      <td>   -0.1950</td> <td>    0.306</td> <td>   -0.638</td> <td> 0.524</td> <td>   -0.794</td> <td>    0.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cassandra</th>    <td>    0.1250</td> <td>    0.353</td> <td>    0.354</td> <td> 0.724</td> <td>   -0.568</td> <td>    0.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pytorch</th>      <td>   -0.7825</td> <td>    0.309</td> <td>   -2.535</td> <td> 0.011</td> <td>   -1.388</td> <td>   -0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caffe</th>        <td>   -0.2779</td> <td>    0.310</td> <td>   -0.897</td> <td> 0.370</td> <td>   -0.885</td> <td>    0.329</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                       Generalized Linear Model Regression Results                       \n",
       "=========================================================================================\n",
       "Dep. Variable:     ['label[DS]', 'label[Other]']   No. Observations:                 5214\n",
       "Model:                                       GLM   Df Residuals:                     5177\n",
       "Model Family:                           Binomial   Df Model:                           36\n",
       "Link Function:                             logit   Scale:                          1.0000\n",
       "Method:                                     IRLS   Log-Likelihood:                -2833.0\n",
       "Date:                           Fri, 11 Oct 2019   Deviance:                       5666.0\n",
       "Time:                                   19:29:57   Pearson chi2:                 5.39e+03\n",
       "No. Iterations:                                5   Covariance Type:             nonrobust\n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       -1.1686      0.049    -23.863      0.000      -1.265      -1.073\n",
       "python           1.0943      0.089     12.306      0.000       0.920       1.269\n",
       "r                0.2770      0.083      3.343      0.001       0.115       0.439\n",
       "sql              1.0346      0.095     10.928      0.000       0.849       1.220\n",
       "spark            0.4800      0.149      3.215      0.001       0.187       0.773\n",
       "hadoop           0.4803      0.154      3.128      0.002       0.179       0.781\n",
       "java            -0.0399      0.115     -0.346      0.729      -0.266       0.186\n",
       "sas              0.5055      0.134      3.777      0.000       0.243       0.768\n",
       "tableau          0.7742      0.166      4.672      0.000       0.449       1.099\n",
       "hive             0.2589      0.206      1.255      0.209      -0.145       0.663\n",
       "scala            0.8433      0.175      4.828      0.000       0.501       1.186\n",
       "c               -0.1030      0.118     -0.876      0.381      -0.333       0.127\n",
       "aws              0.0874      0.136      0.645      0.519      -0.178       0.353\n",
       "tensorflow       1.0283      0.218      4.711      0.000       0.600       1.456\n",
       "matlab          -0.1733      0.129     -1.347      0.178      -0.425       0.079\n",
       "excel            0.3895      0.094      4.130      0.000       0.205       0.574\n",
       "linux           -0.3581      0.132     -2.704      0.007      -0.618      -0.099\n",
       "nosql           -0.3927      0.197     -1.995      0.046      -0.779      -0.007\n",
       "azure           -0.8080      0.211     -3.836      0.000      -1.221      -0.395\n",
       "scikit_learn     0.1994      0.288      0.692      0.489      -0.365       0.764\n",
       "spss             0.5977      0.213      2.805      0.005       0.180       1.015\n",
       "pandas           1.0421      0.357      2.916      0.004       0.342       1.742\n",
       "numpy           -0.1173      0.373     -0.315      0.753      -0.849       0.614\n",
       "pig              1.1821      0.346      3.419      0.001       0.504       1.860\n",
       "d3               0.5832      0.336      1.736      0.083      -0.075       1.242\n",
       "keras            0.9288      0.363      2.559      0.011       0.217       1.640\n",
       "javascript      -0.6604      0.166     -3.980      0.000      -0.986      -0.335\n",
       "c_sharp         -0.3356      0.189     -1.775      0.076      -0.706       0.035\n",
       "perl            -0.8921      0.166     -5.376      0.000      -1.217      -0.567\n",
       "hbase            0.0494      0.362      0.137      0.891      -0.659       0.758\n",
       "docker          -0.7522      0.246     -3.058      0.002      -1.234      -0.270\n",
       "git             -0.0924      0.206     -0.448      0.654      -0.497       0.312\n",
       "mysql            0.0138      0.246      0.056      0.955      -0.468       0.496\n",
       "mongodb         -0.1950      0.306     -0.638      0.524      -0.794       0.404\n",
       "cassandra        0.1250      0.353      0.354      0.724      -0.568       0.818\n",
       "pytorch         -0.7825      0.309     -2.535      0.011      -1.388      -0.177\n",
       "caffe           -0.2779      0.310     -0.897      0.370      -0.885       0.329\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the Wald's Test we see in the above summary table, we see 14 predictors are insignificant, we'll start by dropping these predictors and then will do best subset on the remaining predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = model.pvalues\n",
    "pvals = pvals.reset_index(drop=False)\n",
    "pvals.columns = ['skill', 'pval']\n",
    "preds = []\n",
    "for coefficient in pvals.iterrows():\n",
    "    \n",
    "    if coefficient[1][1] > 0.05 and coefficient[1][0] != 'Intercept':\n",
    "        indeed.drop(coefficient[1][0], axis=1, inplace=True)\n",
    "    else:\n",
    "        preds.append(coefficient[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.remove('Intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python',\n",
       " 'r',\n",
       " 'sql',\n",
       " 'spark',\n",
       " 'hadoop',\n",
       " 'sas',\n",
       " 'tableau',\n",
       " 'scala',\n",
       " 'tensorflow',\n",
       " 'excel',\n",
       " 'linux',\n",
       " 'nosql',\n",
       " 'azure',\n",
       " 'spss',\n",
       " 'pandas',\n",
       " 'pig',\n",
       " 'keras',\n",
       " 'javascript',\n",
       " 'perl',\n",
       " 'docker',\n",
       " 'pytorch']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to implement stepwise selection. Best subset takes too long due to large amount of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3162ac3c65c649ab8c3857f7f858c70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loop...', max=27, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialization variables\n",
    "Y = indeed.label #credit.Balance\n",
    "X = indeed.drop(columns='label', axis=1) #credit.drop(columns = 'Balance', axis = 1)\n",
    "k = X.shape[1]\n",
    "\n",
    "remaining_features = preds\n",
    "features = []\n",
    "features_list = dict()\n",
    "alpha = 0.15\n",
    "\n",
    "for i in tnrange(0,k, desc='Loop...'):\n",
    "    #Variables to add\n",
    "    best_pval = np.inf\n",
    "    best_candidate = None\n",
    "    best_feature = None\n",
    "    \n",
    "    for combo in itertools.combinations(remaining_features,1):\n",
    "        formula = 'label ~ ' + ' + '.join(features + [combo[0]])\n",
    "        candidate = smf.glm(formula, data=indeed, family=sm.families.Binomial()).fit()  #Store temp result \n",
    "\n",
    "        pvals = candidate.pvalues.reset_index(drop=False)\n",
    "        pvals.columns = ['skill', 'pval']\n",
    "        pval = pvals.loc[pvals.shape[0]-1, 'pval']\n",
    "        skill = pvals.loc[pvals.shape[0]-1, 'skill']\n",
    "        if pval < alpha and pval < best_pval:\n",
    "            best_pval = pval\n",
    "            best_candidate = candidate\n",
    "            best_feature = skill\n",
    "\n",
    "    #Check for features to remove\n",
    "    if best_candidate is None: continue\n",
    "    pvals = best_candidate.pvalues.reset_index(drop=False)\n",
    "    pvals.columns = ['skill', 'pval']\n",
    "    for coefficient in pvals.iterrows():\n",
    "        if coefficient[1][1] > alpha and coefficient[1][0] != 'Intercept':\n",
    "            features.remove(coefficient[1][0])\n",
    "    \n",
    "    #Updating variables for next loop\n",
    "    features.append(best_feature)\n",
    "    remaining_features.remove(best_feature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python',\n",
       " 'sql',\n",
       " 'spark',\n",
       " 'sas',\n",
       " 'perl',\n",
       " 'javascript',\n",
       " 'tableau',\n",
       " 'tensorflow',\n",
       " 'scala',\n",
       " 'pig',\n",
       " 'excel',\n",
       " 'docker',\n",
       " 'pandas',\n",
       " 'r',\n",
       " 'azure',\n",
       " 'hadoop',\n",
       " 'linux',\n",
       " 'spss',\n",
       " 'pytorch',\n",
       " 'keras',\n",
       " 'nosql']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'label ~ ' + ' + '.join(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'label ~ python + sql + spark + sas + perl + javascript + tableau + tensorflow + scala + pig + excel + docker + pandas + r + azure + hadoop + linux + spss + pytorch + keras + nosql'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.glm(formula, data=indeed, family=sm.families.Binomial()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>  <td>['label[DS]', 'label[Other]']</td> <th>  No. Observations:  </th>  <td>  5214</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                       <td>GLM</td>              <th>  Df Residuals:      </th>  <td>  5192</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>             <td>Binomial</td>            <th>  Df Model:          </th>  <td>    21</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>              <td>logit</td>             <th>  Scale:             </th> <td>  1.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                     <td>IRLS</td>              <th>  Log-Likelihood:    </th> <td> -2841.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                 <td>Fri, 11 Oct 2019</td>        <th>  Deviance:          </th> <td>  5682.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                     <td>19:30:07</td>            <th>  Pearson chi2:      </th> <td>5.42e+03</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>               <td>5</td>               <th>  Covariance Type:   </th> <td>nonrobust</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   -1.1828</td> <td>    0.048</td> <td>  -24.563</td> <td> 0.000</td> <td>   -1.277</td> <td>   -1.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>python</th>     <td>    1.0498</td> <td>    0.083</td> <td>   12.675</td> <td> 0.000</td> <td>    0.887</td> <td>    1.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sql</th>        <td>    1.0545</td> <td>    0.093</td> <td>   11.344</td> <td> 0.000</td> <td>    0.872</td> <td>    1.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spark</th>      <td>    0.5313</td> <td>    0.143</td> <td>    3.704</td> <td> 0.000</td> <td>    0.250</td> <td>    0.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sas</th>        <td>    0.4973</td> <td>    0.133</td> <td>    3.736</td> <td> 0.000</td> <td>    0.236</td> <td>    0.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>perl</th>       <td>   -0.9498</td> <td>    0.162</td> <td>   -5.877</td> <td> 0.000</td> <td>   -1.267</td> <td>   -0.633</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>javascript</th> <td>   -0.7018</td> <td>    0.156</td> <td>   -4.499</td> <td> 0.000</td> <td>   -1.007</td> <td>   -0.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tableau</th>    <td>    0.8330</td> <td>    0.163</td> <td>    5.097</td> <td> 0.000</td> <td>    0.513</td> <td>    1.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tensorflow</th> <td>    0.9699</td> <td>    0.193</td> <td>    5.020</td> <td> 0.000</td> <td>    0.591</td> <td>    1.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scala</th>      <td>    0.8517</td> <td>    0.166</td> <td>    5.146</td> <td> 0.000</td> <td>    0.527</td> <td>    1.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pig</th>        <td>    1.3020</td> <td>    0.320</td> <td>    4.073</td> <td> 0.000</td> <td>    0.676</td> <td>    1.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>excel</th>      <td>    0.3837</td> <td>    0.094</td> <td>    4.076</td> <td> 0.000</td> <td>    0.199</td> <td>    0.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>docker</th>     <td>   -0.6966</td> <td>    0.235</td> <td>   -2.969</td> <td> 0.003</td> <td>   -1.156</td> <td>   -0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pandas</th>     <td>    1.0528</td> <td>    0.283</td> <td>    3.722</td> <td> 0.000</td> <td>    0.498</td> <td>    1.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>r</th>          <td>    0.2731</td> <td>    0.081</td> <td>    3.377</td> <td> 0.001</td> <td>    0.115</td> <td>    0.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>azure</th>      <td>   -0.7741</td> <td>    0.199</td> <td>   -3.890</td> <td> 0.000</td> <td>   -1.164</td> <td>   -0.384</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hadoop</th>     <td>    0.5072</td> <td>    0.146</td> <td>    3.473</td> <td> 0.001</td> <td>    0.221</td> <td>    0.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>linux</th>      <td>   -0.3674</td> <td>    0.128</td> <td>   -2.866</td> <td> 0.004</td> <td>   -0.619</td> <td>   -0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spss</th>       <td>    0.5967</td> <td>    0.213</td> <td>    2.804</td> <td> 0.005</td> <td>    0.180</td> <td>    1.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pytorch</th>    <td>   -0.8544</td> <td>    0.306</td> <td>   -2.790</td> <td> 0.005</td> <td>   -1.454</td> <td>   -0.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>keras</th>      <td>    0.9677</td> <td>    0.361</td> <td>    2.684</td> <td> 0.007</td> <td>    0.261</td> <td>    1.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nosql</th>      <td>   -0.3659</td> <td>    0.188</td> <td>   -1.950</td> <td> 0.051</td> <td>   -0.734</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                       Generalized Linear Model Regression Results                       \n",
       "=========================================================================================\n",
       "Dep. Variable:     ['label[DS]', 'label[Other]']   No. Observations:                 5214\n",
       "Model:                                       GLM   Df Residuals:                     5192\n",
       "Model Family:                           Binomial   Df Model:                           21\n",
       "Link Function:                             logit   Scale:                          1.0000\n",
       "Method:                                     IRLS   Log-Likelihood:                -2841.0\n",
       "Date:                           Fri, 11 Oct 2019   Deviance:                       5682.0\n",
       "Time:                                   19:30:07   Pearson chi2:                 5.42e+03\n",
       "No. Iterations:                                5   Covariance Type:             nonrobust\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -1.1828      0.048    -24.563      0.000      -1.277      -1.088\n",
       "python         1.0498      0.083     12.675      0.000       0.887       1.212\n",
       "sql            1.0545      0.093     11.344      0.000       0.872       1.237\n",
       "spark          0.5313      0.143      3.704      0.000       0.250       0.812\n",
       "sas            0.4973      0.133      3.736      0.000       0.236       0.758\n",
       "perl          -0.9498      0.162     -5.877      0.000      -1.267      -0.633\n",
       "javascript    -0.7018      0.156     -4.499      0.000      -1.007      -0.396\n",
       "tableau        0.8330      0.163      5.097      0.000       0.513       1.153\n",
       "tensorflow     0.9699      0.193      5.020      0.000       0.591       1.349\n",
       "scala          0.8517      0.166      5.146      0.000       0.527       1.176\n",
       "pig            1.3020      0.320      4.073      0.000       0.676       1.929\n",
       "excel          0.3837      0.094      4.076      0.000       0.199       0.568\n",
       "docker        -0.6966      0.235     -2.969      0.003      -1.156      -0.237\n",
       "pandas         1.0528      0.283      3.722      0.000       0.498       1.607\n",
       "r              0.2731      0.081      3.377      0.001       0.115       0.432\n",
       "azure         -0.7741      0.199     -3.890      0.000      -1.164      -0.384\n",
       "hadoop         0.5072      0.146      3.473      0.001       0.221       0.793\n",
       "linux         -0.3674      0.128     -2.866      0.004      -0.619      -0.116\n",
       "spss           0.5967      0.213      2.804      0.005       0.180       1.014\n",
       "pytorch       -0.8544      0.306     -2.790      0.005      -1.454      -0.254\n",
       "keras          0.9677      0.361      2.684      0.007       0.261       1.675\n",
       "nosql         -0.3659      0.188     -1.950      0.051      -0.734       0.002\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Mis-classification Error rate with a threshold of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction_prob'] = model.predict(test)\n",
    "test.loc[test.prediction_prob > 0.5, 'prediction'] = 'DS'\n",
    "test.prediction.fillna('Other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['flag'] = test.label != test.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2553191489361702"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.flag.sum() / test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Mis-Classification error rates at other thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq(start, stop, step):\n",
    "    while start <= stop:\n",
    "        yield start\n",
    "        start = round(start+step, 2)\n",
    "    \n",
    "s = seq(0.1, 0.9, 0.01)\n",
    "\n",
    "threshold = []\n",
    "misclass_error = []\n",
    "\n",
    "for i in s:\n",
    "    if i == 0.91:\n",
    "        s.close()\n",
    "    threshold.append(i)\n",
    "    test.loc[test.prediction_prob > i, 'prediction'] = 'DS'\n",
    "    test.loc[test.prediction_prob < i, 'prediction'] = 'Other'    \n",
    "    test['flag'] = test.label != test.prediction\n",
    "    misclass_error.append(test.flag.sum() / test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Want to check for Multicollinearity, so calculated Efron's Pseudo $R^2$ and VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = []\n",
    "X = indeed[features]\n",
    "for feature in features:\n",
    "    x_feature = features.copy()\n",
    "    x_feature.remove(feature)\n",
    "    formula = feature + ' ~ ' + ' + '.join(x_feature)\n",
    "    m = smf.glm(formula, data=X, family=sm.families.Binomial()).fit()\n",
    "    predictions = m.predict(X)\n",
    "    numerator = X[feature] - predictions\n",
    "    numerator = numerator.to_numpy() @ numerator.to_numpy()\n",
    "    denominator = X[feature] - X[feature].mean()\n",
    "    denominator = denominator.to_numpy() @ denominator.to_numpy()\n",
    "    R2.append(1 - (numerator / denominator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46437742750065114,\n",
       " 0.3256285579606303,\n",
       " 0.5063407106267137,\n",
       " 0.24198736339014182,\n",
       " 0.10784873181319099,\n",
       " 0.05090654334319655,\n",
       " 0.19055778590768724,\n",
       " 0.39968215384800565,\n",
       " 0.24090886071593554,\n",
       " 0.15654210547553593,\n",
       " 0.09387088028439516,\n",
       " 0.09504872833004963,\n",
       " 0.09117332347894935,\n",
       " 0.3037216022612116,\n",
       " 0.051790808860393334,\n",
       " 0.4866136206974736,\n",
       " 0.09710186201454107,\n",
       " 0.2032831228431463,\n",
       " 0.2734825061577294,\n",
       " 0.3252485205369269,\n",
       " 0.18122372702200507]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### None of the VIF values are greater than 4, so no suspection of multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF = list(map(lambda x: 1/(1-x), R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8669862909879804,\n",
       " 1.4828623183922134,\n",
       " 2.0256886105992797,\n",
       " 1.3192392206974386,\n",
       " 1.1208861497584155,\n",
       " 1.0536370185529629,\n",
       " 1.2354186408740415,\n",
       " 1.6657842281550468,\n",
       " 1.317364869972199,\n",
       " 1.1855956373065821,\n",
       " 1.103595479101099,\n",
       " 1.1050318744286105,\n",
       " 1.1003198143654376,\n",
       " 1.436207131009045,\n",
       " 1.0546196022400378,\n",
       " 1.9478506643642832,\n",
       " 1.1075446475404127,\n",
       " 1.255151018726474,\n",
       " 1.3764293475046085,\n",
       " 1.4820271321164649,\n",
       " 1.221334854224428]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
